#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Sep  9 16:54:15 2020

@author: phg17
"""

import logging
import shutil
import psutil

# Installed library
import pickle
import numpy as np
import pandas as pd
import h5py # for mat file version >= 7.3
from scipy import signal as scisig
from scipy.io import loadmat
from scipy.io.wavfile import read as wavread
import os.path as ospath
#import utils
from .utils import lag_finder, AddNoisePostNorm, signal_envelope

# MNE:
import mne
from mne.preprocessing.ica import ICA


Conditions_EEG = dict()
Conditions_EEG[0] = {'type':'audio','delay':0,'correlated':True} #audio only
Conditions_EEG[1] = {'type':'tactile','delay':0,'correlated':True} #tactile only
Conditions_EEG[2] = {'type':'audio-tactile','delay':60,'correlated':True} #audio tactile -60 (late tactile)
Conditions_EEG[3] = {'type':'audio-tactile','delay':0,'correlated':True} #audio tactile 0 (sync advance)
Conditions_EEG[4] = {'type':'audio-tactile','delay':-60,'correlated':True} #audio tactile 60 (tactile in advance)
Conditions_EEG[5] = {'type':'audio-tactile','delay':-120,'correlated':True} #audio tactile 120 (tactile in advance)
Conditions_EEG[6] = {'type':'audio-tactile','delay':-180,'correlated':True} #audio tactile 120 (tactile in advance)
Conditions_EEG[7] = {'type':'audio-tactile','delay':0,'correlated':False} #uncorrelated (tactile uncorrelated)

Bad_trial = dict()
Bad_trial['deb1'] = True


path_data = '/home/phg17/Documents/EEG Experiment/Data Analysis/Data'
path_stimuli = '/home/phg17/Documents/EEG Experiment/Stimuli_Odin/Stimuli' 

def load_mat(fname):
    """
    Loading simple mat file into dictionnary

    Parameters
    ----------
    fname : str
        Absolute path of file to be loaded

    Returns
    -------
    data : dict
        Dictionnary containing variables from .mat file
        (each variables is a key/value pair)
    """
    try:
        data = loadmat(fname)
    except NotImplementedError:
        print(".mat file is from matlab v7.3 or higher, will use HDF5 format.")
        with h5py.File(fname, mode='r') as fid:
            data = {}
            for k, val in fid.iteritems():
                data[k] = val.value
    return data


def load_eeg_data(name, session, Fs = 1000, low_freq = 1, high_freq = 20 , ica_data=False):
    """"
    Load eeg brainvision structure and returns data, channel names,
    sampling frequency and other useful data in a tuple

    Parameters
    ----------
    fname : str
        File path to .set EEGLAB file

    Returns
    -------
    eeg : ndarray
    srate : float
    time : ndarray
        Vector of time points
    events : ndarray
        Array of event onsets
    event_type : list
        Event type or names
    chnames : list
    stimtrack, button Press, Diode : ndarray
    """
    
    fname = ospath.join(path_data,name,'Session ' + str(session),name + '.vhdr')
    fpreload = ospath.join(path_data,name,'Session ' + str(session),name + "_preload")
    raw = mne.io.read_raw_brainvision(fname, preload = fpreload, verbose='ERROR')
    raw.set_eeg_reference('average', projection=True)
    F_eeg = raw.info['sfreq']
    if Fs != F_eeg:
        raw.filter(1,Fs/2,h_trans_bandwidth=2,verbose='ERROR')
        raw.resample(Fs)
        
    raw.filter(low_freq,high_freq,h_trans_bandwidth=2,verbose='ERROR')
    
    
    if ica_data:
        print('ICA is not set up properly, try to use the same shpere...etc files for everything')
        ica = ICA(n_components = 10, random_state = 97)
        ica.fit(raw)
        ica.exclude = [0]
        ica.apply(raw)
    
    chnames= raw.ch_names
    time = raw.times
    srate = raw.info['sfreq']
    eeg = raw.get_data()[:63]
    events = mne.events_from_annotations(raw,'auto',verbose='ERROR')[0][:].T[0][1:]
    stimtrack = raw['Sound'][0][0]
    button = raw['Button'][0][0]
    diode = raw['Diode'][0][0]
    #raw.drop_channels(['Sound','Diode','Button'])
    
    return chnames, time, srate, events, eeg, stimtrack, button, diode, raw.info


def extract_duration_praat(fname):
    """Function to get the duration from a file generated by PrAat software,
    for instance to get envelope or pitch of a sound. The duration is extracted from
    the header of such files.

    Parameters
    ----------
    filepath : str
        Path of audio file

    Returns
    -------
    dur : float
        Duration of audio
    """
    with open(fname, 'r') as fid:
        headers = fid.readlines(80)
        duration = float(headers[4])
        return duration
    
    
def param_load(name, session):
    """Function to load the order of chapters and condition for each subject.

    Parameters
    ----------
    name : str
        ID of the subject
    Returns
    -------
    chapters : list
    parameters : list
    """
    
    fchapters = ospath.join(path_data,name,'Session ' + str(session),"chapters_1.npy")
    fparameters = ospath.join(path_data,name,'Session ' + str(session),"parameters_1.npy")
    
    chapters = np.load(fchapters)
    parameters = np.flip(np.load(fparameters))
    
    return chapters, parameters
    

def stimuli_load(path, chapter, part, Fs=39062.5):
    """Function to load the stimuli linked to a trial and resample them to the wanted frequency.

    Parameters
    ----------
    chapters : int
    part : int
    Returns
    -------
    chapters : list
    parameters : list
    """
    F_stim = 39062.5
    file = ospath.join(path,"Odin_" + str(chapter) + '_' + str(part))
    audio = np.load(file + '_audio.npy')
    tactile = np.load(file + '_phone_.npy')
    dirac = np.load(file + '_dirac.npy')
    noise = np.load(ospath.join(path, 'Odin_SSN.npy'))
    
    if Fs != F_stim:
        audio = resample(audio,39062.5,Fs)
        tactile = resample(tactile,39062.5,Fs)
        dirac = resample(dirac,39062.5,Fs,method='dirac')
        
    
    return audio, tactile, dirac, noise

    
        

def resample(data, Fs, F_resampling, method = 'continuous'):
    """Function to apply an anti-aliasing filter before resampling data

    Parameters
    ----------
    data : ndarray
    mode : decide if the signal is continuous or binary/discrete
    Returns
    -------
    out : resampled data without aliasing
    """
    
    if method == 'continuous':
        filtered_data = mne.filter.filter_data(data,Fs, l_freq = 1, h_freq = F_resampling/2., verbose = 'WARNING')
        out = mne.filter.resample(filtered_data,up = F_resampling, down = Fs, npad = 'auto')
        #ntaps = fir_order(10, Fs, ripples=1e-3)  # + 1 -> using odd ntaps for Type I filter,
                                                    # so I have an integer group delay (instead of half)
        #b = scisig.firwin(ntaps, F_resampling/2, fs=Fs)
        #filtered_data = scisig.convolve(np.pad(out, (len(b) // 2, len(b) // 2), mode='edge'),
                            #b, mode='valid')
    elif method == 'dirac':
        new_length = int(len(data) / Fs * F_resampling)+1
        out = np.zeros(new_length)
        for sample in range(len(data)):
            if data[sample] != 0:
                out[int(sample / Fs * F_resampling)] = 1
    else:
        raise ValueError("Method can only be 'continuous' or 'dirac'.")
        
    return out

        

def get_data_trial(name, session, n_trial, Fs):
    """Function to load all the information regarding a single trial of a 
    single subject. 

    Parameters
    ----------
    name : str
        ID of the subject
    n_trial : int
        number of trial, for an eeg session, there should be 16
    Fs : float
        Sampling Frequency to work with, resampling is handled already
    -------
    stimtrack : ndarray
        The stimuli as recorded by the Amplifier, useful for alignment, test
    audio : ndarray
        The audio stimuli, useful to extract features
    """
    path_stimuli = '/home/phg17/Documents/EEG Experiment/Stimuli_Odin/Stimuli' 
    
    chnames, time, srate, events, eeg, stimtrack, button, diode, info = load_eeg_data(name,session,Fs)
    chapters, parameters = param_load(name,session)
    chapter = chapters[n_trial//4]
    part = n_trial%4 + 1
    parameter = parameters[n_trial]
    
    audio, tactile, dirac, noise = stimuli_load(path_stimuli, chapter, part, Fs)
    
    start_trial = events[n_trial]
    length_trial = len(audio)
    end_trial = start_trial + length_trial
    timescale = np.arange(length_trial)
    stimtrack = mne.filter.filter_data(stimtrack[start_trial:end_trial],Fs,1,h_freq=None, verbose='ERROR')
    condition = Conditions_EEG[parameter]
    tactile = np.roll(tactile,int(condition['delay']/ 1000 * Fs))
    dirac = np.roll(dirac,int(condition['delay']/ 1000 * Fs))
    audio_noise = AddNoisePostNorm(audio,noise,-2)
    if condition['type'] == 'tactile':
        delay = lag_finder(stimtrack,tactile,Fs)
    elif condition['type'] == 'audio' or not condition['correlated']:
        delay = lag_finder(stimtrack,audio_noise,Fs)
    else:
        delay = lag_finder(stimtrack,audio_noise + tactile*2000,Fs)
  
    print(delay)
    #eeg = np.roll(eeg,-delay,axis=1)[:,start_trial:end_trial]
    #eeg = eeg[:,start_trial+delay:end_trial+delay]
    eeg = eeg[:,start_trial:end_trial]
    return stimtrack, eeg, audio, tactile, dirac, parameter, condition, timescale, info
    

def Align_and_Save(name, session, F_resample, Fs=1000):
    """Function to load all the information regarding a single trial of a 
    single subject. 

    Parameters
    ----------
    name : str
        ID of the subject
    session : int
        session of recording = 1 or 2
    Fs : float
        Sampling Frequency of EEG, no resampling
    F_resample : float
        Sampling Frequency to work with and save the data as
    -------
    stimtrack : ndarray
        The stimuli as recorded by the Amplifier, useful for alignment, test
    audio : ndarray
        The audio stimuli, useful to extract features
    """
    cond_count = dict()
    cond_count[0] = session *2 - 2
    cond_count[1] = session *2 - 2
    cond_count[2] = session *2 - 2
    cond_count[3] = session *2 - 2
    cond_count[4] = session *2 - 2
    cond_count[5] = session *2 - 2
    cond_count[6] = session *2 - 2
    cond_count[7] = session *2 - 2
    path_save = ospath.join(path_data, str(F_resample) + 'Hz')
    chnames, time, srate, events, eeg, stimtrack, button, diode, info = load_eeg_data(name,session,Fs)
    print(events)
    chapters, parameters = param_load(name,session)
    start = 0
    end = 16
    if name == 'deb':
        start = 1
    
    for n_trial in range(start,end):
        
        chapter = chapters[n_trial//4]
        part = n_trial%4 + 1
        parameter = parameters[n_trial]
        audio, tactile, dirac, noise = stimuli_load(path_stimuli, chapter, part, Fs)
        if name == 'deb':
            start_trial = events[n_trial-1]    
            
        else:    
            start_trial = events[n_trial]
        
        length_trial = len(audio)
        end_trial = start_trial + length_trial
        timescale = np.arange(length_trial)
        #stimtrack = mne.filter.filter_data(stimtrack[start_trial:end_trial],1000,1,h_freq=None, verbose='ERROR')
        stimtrack_current = stimtrack[start_trial:end_trial]
        condition = Conditions_EEG[parameter]
        tactile = np.roll(tactile,int(condition['delay']/ 1000 * Fs))
        dirac = np.roll(dirac,int(condition['delay']/ 1000 * Fs))
        audio_noise = AddNoisePostNorm(audio,noise,-2)
        print(condition)
        if condition['type'] == 'tactile':
            delay = lag_finder(stimtrack_current,tactile,Fs)
        elif condition['type'] == 'audio' or not condition['correlated']:
            delay = lag_finder(stimtrack_current,audio_noise,Fs)
        else:
            delay = lag_finder(stimtrack_current,audio_noise + tactile*2000,Fs)
        print(delay)
        #eeg = np.roll(eeg,-delay,axis=1)[:,start_trial:end_trial]
        #eeg = eeg[:,start_trial+delay:end_trial+delay]
        eeg_current = eeg[:,start_trial+delay:end_trial+delay]
        
        trial = dict()
        audio, tactile, dirac, noise = stimuli_load(path_stimuli, chapter, part, F_resample)
        syllables = np.copy(dirac)
        tactile = np.roll(tactile,int(condition['delay']/ 1000 * F_resample))
        dirac = np.roll(dirac,int(condition['delay']/ 1000 * F_resample))
        envelope = signal_envelope(audio, F_resample, cutoff=20, method='hilbert', resample = None)
        eeg_current = mne.filter.resample(eeg_current,up = F_resample, down = Fs)
        trial['condition'] = condition
        trial['response'] = eeg_current
        trial['envelope'] = envelope
        trial['dirac'] = dirac[:len(envelope)]
        trial['syllables'] = syllables[:len(envelope)]
        trial['tactile'] = tactile[:len(envelope)]
        
        
        count = cond_count[parameter]
        cond_count[parameter] += 1
        
        if not condition['correlated']:
            filename = 'uncorrelated_' + name + '_' + str(F_resample) + 'Hz_' + str(count) + '_' +  '.pkl'  
        elif condition['type'] == 'audio-tactile':
            filename = 'audio_tactile_' + str(condition['delay']) + '_' + name + '_' + str(F_resample) + 'Hz_' + str(count) + '_' +  '.pkl'  
        else:
            filename = str(condition['type']) + '_' + name + '_' + str(F_resample) + 'Hz_' + str(count) + '_' +  '.pkl'  
        file = ospath.join(path_save,filename)
        print(file)
    
        output = open(file, 'wb')
        pickle.dump(trial, output)
        output.close()
        
        
def get_name(parameter,name,count,Fs):
    path_save = ospath.join(path_data, str(Fs) + 'Hz')
    condition = Conditions_EEG[parameter]
    if not condition['correlated']:
        filename = 'uncorrelated_' + name + '_' + str(Fs) + 'Hz_' + str(count) + '_' +  '.pkl'  
    elif condition['type'] == 'audio-tactile':
        filename = 'audio_tactile_' + str(condition['delay']) + '_' + name + '_' + str(Fs) + 'Hz_' + str(count) + '_' +  '.pkl'  
    else:
        filename = str(condition['type']) + '_' + name + '_' + str(Fs) + 'Hz_' + str(count) + '_' +  '.pkl'  
    file = ospath.join(path_save,filename)
    
    return file

def raw_info():
    name = 'jon'
    session = 1
    fname = ospath.join(path_data,name,'Session ' + str(session),name + '.vhdr')
    fpreload = ospath.join(path_data,name,'Session ' + str(session),name + "_preload")
    raw = mne.io.read_raw_brainvision(fname, preload = fpreload, verbose='ERROR')
    raw.set_eeg_reference('average', projection=True)
    return raw.info
    
    
    
    
    
    
    